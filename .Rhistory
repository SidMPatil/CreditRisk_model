data = read.csv("credit risk data.csv", header = TRUE)
View(data)
data = read.csv("credit risk data.csv", header = TRUE)
str(data)
summary(data)
install.packages("dummies")
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data$purpose, dummy(data$purpose, sep = "_"))
data
data = read.csv("credit risk data.csv", header = TRUE)
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data
View(data)
data = read.csv("credit risk data.csv", header = TRUE)
summary(data)
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data = data[,-c(2)]
data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data = read.csv("credit risk data.csv", header = TRUE)
summary(data)
data = read.csv("credit risk data.csv", header = TRUE)
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data = data[,-c(2)]
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
data_norm = as.data.frame(lapply(data, normalize))
data_norm
data_norm
data_norm$not.fully.paid = as.factor(data_norm$not.fully.paid)
data_norm
Log_reg = glm(not.fully.paid ~ ., data_norm, family = "binomial")
#summary(NB) # to identify the significant attributes (Pr(>|z|) < 0.05)
library(broom)
tm = tidy(Log_reg) #data frame with model summary parameters as columns
# get variables with p value less than 0.05
library(dplyr)
sign_variables = tm$term[tm$p.value < 0.05] %>% paste(collapse = " + ")
sign_variables = paste0('not.fully.paid', ' ~ ', sign_variables)
#sign_variables
sign_variables
sign_variables
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, data_norm, family = "binomial")
log_regr
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, data_norm, family = "binomial")
summary(log_regr)
# ## 75% of the sample size
smp_size = floor(0.75 * nrow(data_norm))
## set the seed to make your partition reproducible
set.seed(12345)
train_ind = sample(seq_len(nrow(data_norm)), size = smp_size)
train_data = data_norm[train_ind, ]
test_data = data_norm[-train_ind, ]
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, train_data, family = "binomial")
summary(log_regr)
test_predictions = predict(log_regr, newdata = test_data)
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, test_predictions))
test_predictions = predict(log_regr, newdata = test_data)
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, test_predictions))
test_predictions
train_data
summary(train_data)
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, train_data, family = "binomial")
summary(log_regr)
test_predictions = predict(log_regr, newdata = test_data)
test_data$not.fully.paid
test_predictions
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, test_predictions, type = "response"))
test_predictions = predict(log_regr, newdata = test_data, type = "response")
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, test_predictions))
test_predictions
View(test_predictions)
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
#ROC curve
roc.curve(test_data$not.fully.paid, test_predictions)
test_predictions = predict(log_regr, newdata = test_data, type = "response")
test_data$predictied.risk = test_predictions
library(ROCR)
require(ROCR)
pred = prediction(test_data$predictied.risk, test_data$not.fully.paid)
pred
as.numeric(performance(pred, "auc")@y.values)
predictTrain = predict(log_regr, type="response")
predictTrain
ROCRpred = prediction(predictTrain, train_data$not.fully.paid)
ROCRpred
ROCRperf = performance(ROCRpred, "tpr", "fpr")
ROCRperf
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
library(ROCR)
require(ROCR)
pred = prediction(test_data$predictied.risk, test_data$not.fully.paid)
pred
library(ROCR)
require(ROCR)
pred = prediction(test_data$predictied.risk, test_data$not.fully.paid)
#pred
as.numeric(performance(pred, "auc")@y.values)
predictTrain = predict(log_regr, type="response")
#predictTrain
ROCRpred = prediction(predictTrain, train_data$not.fully.paid)
#ROCRpred
ROCRperf = performance(ROCRpred, "tpr", "fpr")
#ROCRperf
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
t1 = table(test_data$not.fully.paid, as.numeric(test_data$predicted.risk >= 0.35))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
t1 = table(test_data$not.fully.paid, as.numeric(test_data$predictied.risk >= 0.35))
t1
t1
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
data = read.csv("credit risk data.csv", header = TRUE)
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data = data[,-c(2)]
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
data_norm = as.data.frame(lapply(data, normalize))
data_norm$not.fully.paid = as.factor(data_norm$not.fully.paid)
Log_reg = glm(not.fully.paid ~ ., data_norm, family = "binomial")
#summary(NB) # to identify the significant attributes (Pr(>|z|) < 0.05)
library(broom)
tm = tidy(Log_reg) #data frame with model summary parameters as columns
# get variables with p value less than 0.05
library(dplyr)
sign_variables = tm$term[tm$p.value < 0.05] %>% paste(collapse = " + ")
sign_variables = paste0('not.fully.paid', ' ~ ', sign_variables)
#sign_variables
# ## 75% of the sample size
smp_size = floor(0.75 * nrow(data_norm))
## set the seed to make your partition reproducible
set.seed(12345)
train_ind = sample(seq_len(nrow(data_norm)), size = smp_size)
train_data = data_norm[train_ind, ]
test_data = data_norm[-train_ind, ]
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, train_data, family = "binomial")
summary(log_regr)
test_predictions = predict(log_regr, newdata = test_data, type = "response")
test_data$predictied.risk = test_predictions
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
library(ROCR)
require(ROCR)
pred = prediction(test_data$predictied.risk, test_data$not.fully.paid)
#pred
as.numeric(performance(pred, "auc")@y.values)
predictTrain = predict(log_regr, type="response")
#predictTrain
ROCRpred = prediction(predictTrain, train_data$not.fully.paid)
#ROCRpred
ROCRperf = performance(ROCRpred, "tpr", "fpr")
#ROCRperf
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
data = read.csv("credit risk data.csv", header = TRUE)
View(data)
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data = data[,-c(2)]
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
data_norm = as.data.frame(lapply(data, normalize))
data_norm$not.fully.paid = as.factor(data_norm$not.fully.paid)
Log_reg = glm(not.fully.paid ~ ., data_norm, family = "binomial")
#summary(NB) # to identify the significant attributes (Pr(>|z|) < 0.05)
library(broom)
tm = tidy(Log_reg) #data frame with model summary parameters as columns
# get variables with p value less than 0.05
library(dplyr)
sign_variables = tm$term[tm$p.value < 0.05] %>% paste(collapse = " + ")
sign_variables = paste0('not.fully.paid', ' ~ ', sign_variables)
#sign_variables
# ## 75% of the sample size
smp_size = floor(0.75 * nrow(data_norm))
## set the seed to make your partition reproducible
set.seed(12345)
train_ind = sample(seq_len(nrow(data_norm)), size = smp_size)
train_data = data_norm[train_ind, ]
test_data = data_norm[-train_ind, ]
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, train_data, family = "binomial")
summary(log_regr)
test_predictions = predict(log_regr, newdata = test_data, type = "response")
test_data$predictied.risk = test_predictions
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.7)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.8)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.9)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.1)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.95)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.6)))
View(data_norm)
summary(data$not.fully.paid)
levels(data$not.fully.paid)
dats %>% group_by(not.fully.paid) %>% summarise(no_rows = length(not.fully.paid))
data %>% group_by(not.fully.paid) %>% summarise(no_rows = length(not.fully.paid))
data = read.csv("credit risk data.csv", header = TRUE)
data %>% group_by(not.fully.paid) %>% summarise(no_rows = length(not.fully.paid))
#Creating dummy variables for 'purpose' variable
library(dummies)
data = cbind(data, dummy(data$purpose, sep = "_"))
data = data[,-c(2)]
#Normalization
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }
data_norm = as.data.frame(lapply(data, normalize))
data_norm$not.fully.paid = as.factor(data_norm$not.fully.paid)
Log_reg = glm(not.fully.paid ~ ., data_norm, family = "binomial")
#summary(NB) # to identify the significant attributes (Pr(>|z|) < 0.05)
library(broom)
tm = tidy(Log_reg) #data frame with model summary parameters as columns
# get variables with p value less than 0.05
library(dplyr)
sign_variables = tm$term[tm$p.value < 0.05] %>% paste(collapse = " + ")
sign_variables = paste0('not.fully.paid', ' ~ ', sign_variables)
#sign_variables
# ## 75% of the sample size
smp_size = floor(0.75 * nrow(data_norm))
## set the seed to make your partition reproducible
set.seed(12345)
train_ind = sample(seq_len(nrow(data_norm)), size = smp_size)
train_data = data_norm[train_ind, ]
test_data = data_norm[-train_ind, ]
log_regr = glm(not.fully.paid ~ int.rate + installment + log.annual.inc + revol.util + inq.last.6mths + pub.rec + annualincome + data_credit_card + data_debt_consolidation, train_data, family = "binomial")
summary(log_regr)
test_predictions = predict(log_regr, newdata = test_data, type = "response")
test_data$predictied.risk = test_predictions
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.6)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.7)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.8)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.6)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.75)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.6)))
library(ROCR)
require(ROCR)
pred = prediction(test_data$predictied.risk, test_data$not.fully.paid)
#pred
as.numeric(performance(pred, "auc")@y.values)
predictTrain = predict(log_regr, type="response")
#predictTrain
ROCRpred = prediction(predictTrain, train_data$not.fully.paid)
#ROCRpred
ROCRperf = performance(ROCRpred, "tpr", "fpr")
#ROCRperf
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.5)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.6)))
test_data
View(test_data)
View(data)
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.4)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.7)))
#Confusion matrix
library(caret)
confusionMatrix(table(test_data$not.fully.paid, as.numeric(test_predictions >= 0.6)))
